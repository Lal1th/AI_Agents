{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkBBsFjCv0SuSAgJ7OBZrB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uj25i_WUOJ6L"},"outputs":[],"source":["import pandas as pd\n","!pip install -q -U google-generativeai"]},{"cell_type":"code","source":["emissions=pd.read_parquet(\"/content/su_emission_audit.parquet\")"],"metadata":{"id":"E8a6d5ejO8V9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Explain the Emission -button"],"metadata":{"id":"WRL-L84McdRR"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import google.generativeai as genai\n","from datetime import datetime, timezone\n","from google.colab import userdata\n","\n","try:\n","    genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n","except Exception as e:\n","    print(f\"ERROR: Failed to configure Gemini API. Ensure GEMINI_API_KEY is set in Colab secrets. Details: {e}\")\n","    exit()\n","\n","\n","# --- Data Processing Functions ---\n","\n","def format_duration(start_str, end_str):\n","    \"\"\"\n","    Calculates and formats duration. If duration is over 72 hours, it returns days.\n","    \"\"\"\n","    try:\n","        start_time = pd.to_datetime(start_str)\n","        end_time = pd.to_datetime(end_str)\n","        duration_delta = end_time - start_time\n","\n","        total_minutes = int(duration_delta.total_seconds() / 60)\n","        hours = total_minutes // 60\n","\n","        # --- MODIFIED: Check for duration greater than 72 hours ---\n","        if hours > 72:\n","            days = hours // 24\n","            return f\"{days} days\"\n","\n","        # Original logic for durations less than or equal to 72 hours\n","        minutes = total_minutes % 60\n","        if hours > 0 and minutes > 0:\n","            return f\"{hours} hours and {minutes} minutes\"\n","        elif hours > 0:\n","            return f\"{hours} hours\"\n","        else:\n","            return f\"{minutes} minutes\"\n","    except (ValueError, TypeError):\n","        return \"an unknown duration\"\n","\n","def get_emission_context(current_rate, historical_rate):\n","    \"\"\"Compares current rate to historical average to generate context.\"\"\"\n","    if pd.isna(historical_rate) or historical_rate == 0:\n","        return {\"descriptor\": \"\", \"comparison\": \"historical data is not available\"}\n","\n","    try:\n","        percent_diff = ((current_rate - historical_rate) / historical_rate) * 100\n","        comparison_text = f\"{abs(percent_diff):.0f}%\"\n","\n","        if percent_diff > 25:\n","            descriptor = \"high-rate\"\n","            comparison_text += \" higher\"\n","        elif percent_diff < -25:\n","            descriptor = \"low-rate\"\n","            comparison_text += \" lower\"\n","        else:\n","            descriptor = \"\"\n","            comparison_text += \" higher\" if percent_diff > 0 else \" lower\"\n","\n","        return {\"descriptor\": descriptor, \"comparison\": comparison_text}\n","    except (ValueError, TypeError):\n","        return {\"descriptor\": \"\", \"comparison\": \"historical data could not be compared\"}\n","\n","# --- Main Gemini API Function ---\n","\n","def explain_emission(emission_data):\n","    \"\"\"Takes a dictionary of processed emission data and generates a narrative.\"\"\"\n","    duration = format_duration(emission_data.get(\"ee_startTime\"), emission_data.get(\"ee_endTime\"))\n","    context = get_emission_context(emission_data.get(\"ee_emissionsRate\"), emission_data.get(\"historical_average_rate\"))\n","    detection_date_str = pd.to_datetime(emission_data.get(\"ee_startTime\")).strftime('%b %d, %Y')\n","\n","    # --- MODIFIED: Prompt instructions are now conditional ---\n","    prompt = f\"\"\"\n","    You are an expert assistant for an emissions management platform. Your task is to translate raw emission data into a concise, human-readable narrative paragraph.\n","\n","    Follow these rules for the narrative:\n","    1. Start with the emission rate, severity (if applicable), and asset name.\n","    2. State the duration and the total resulting volume.\n","    3. If historical data is provided in the data section below (i.e., not 'not available'), provide context by comparing the current rate to the historical average. Otherwise, do not mention historical data at all.\n","    4. Mention how and when the emission was first detected.\n","    5. Conclude with the likely source or cause. If a specific cause is provided, use it.\n","\n","    Here is the data for the emission event:\n","    - Emission Rate: {emission_data.get('ee_emissionsRate')} kg/h\n","    - Total Volume: {emission_data.get('ee_emissionsVolume')} kg\n","    - Asset Name: '{emission_data.get('a_name')}'\n","    - Duration: {duration}\n","    - Detection Method: {emission_data.get('eo_detectionSource')}\n","    - Detection Date: {detection_date_str}\n","    - Source Category: {emission_data.get('ee_sourceCategory')}\n","    - Specific Cause: {emission_data.get('ee_sourceEmissionsCause', 'Not specified')}\n","    - Severity Descriptor: '{context.get('descriptor')}'\n","    - Historical Comparison: '{context.get('comparison')}'\n","\n","    Now, generate the single paragraph explanation based on this data.\n","    \"\"\"\n","\n","    model = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n","    response = model.generate_content(prompt)\n","\n","    return response.text\n","\n","# --- Main Execution Logic ---\n","\n","# 1. Calculate historical average rate for each asset (using a_FLOC as unique ID)\n","historical_averages = emissions.groupby('a_FLOC')['ee_emissionsRate'].mean().reset_index()\n","historical_averages = historical_averages.rename(columns={'ee_emissionsRate': 'historical_average_rate'})\n","\n","# 2. Merge historical averages back into the main DataFrame\n","emissions_with_history = pd.merge(emissions, historical_averages, on='a_FLOC', how='left')\n","\n","# 3. Select a single event to explain\n","#    change this to get data from the current viewing record (button action record)\n","event_index_to_explain = 10\n","single_emission_event = emissions_with_history.iloc[event_index_to_explain]\n","\n","# 4. Convert the row (Pandas Series) to a dictionary for our function\n","data_for_gemini = single_emission_event.to_dict()\n","\n","# 5. Generate the story and print it\n","if not data_for_gemini:\n","    print(f\"Could not retrieve data for event at index {event_index_to_explain}.\")\n","else:\n","    print(f\"--- Generating story for event at index: {event_index_to_explain} ---\")\n","    emission_story = explain_emission(data_for_gemini)\n","    print(emission_story)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"dvsLHc-YUiFg","executionInfo":{"status":"ok","timestamp":1757353693319,"user_tz":360,"elapsed":1412,"user":{"displayName":"Lalith Nandakumar","userId":"16651296496712072419"}},"outputId":"ae6fc6dc-1c5b-482c-fb76-a18b35f5c32a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Generating story for event at index: 10 ---\n","CHAPMAN STATE BAT experienced a low-rate emission event at a rate of 2.74 kg/h, resulting in a total volume of 12,802.84 kg over 194 days.  Detected by Bridger Photonics on August 10, 2021, this emission rate is 86% lower than the historical average.  The specific cause remains undetermined.\n","\n"]}]}]}